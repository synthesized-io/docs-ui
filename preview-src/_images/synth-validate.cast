{"version": 2, "width": 120, "height": 20, "timestamp": 1649079554, "idle_time_limit": 1.0, "env": {"SHELL": "/bin/bash", "TERM": "xterm-256color"}, "title": "Validate Synthesized"}
[0.30491, "o", "\u001b]0;synthesized@synthesized-sdk: ~\u0007\u001b[01;32msynthesized@synthesized-sdk\u001b[00m:\u001b[01;34m~\u001b[00m$ "]
[0.493724, "o", "s"]
[0.563419, "o", "y"]
[0.674829, "o", "n"]
[0.721944, "o", "t"]
[0.7877097, "o", "h"]
[1.1219272, "o", "-"]
[1.535302, "o", "v"]
[1.620342, "o", "a"]
[1.670634, "o", "l"]
[1.737918, "o", "i"]
[1.76723, "o", "d"]
[1.8420563, "o", "a"]
[1.994987, "o", "t"]
[2.08206, "o", "e"]
[2.426841, "o", "\r\n"]
[2.495151, "o", "\r\n               _   _           _           _  .        \u001b[38;5;210m_____ ____  _____\u001b[39m\r\n   ___ _ _ ___| |_| |_ ___ ___|_|___ ___ _| |/___     \u001b[38;5;211m|   __|    \\|  |  |\u001b[39m\r\n  |_ -| | |   |  _|   | -_|_ -| |- _| -_| . ||_ -|    \u001b[38;5;212m|___  |  |  |    -|\u001b[39m\r\n  |___|_  |_|_|_| |_|_|___|___|_|___|___|___||___|    \u001b[38;5;213m|_____|____/|__|__|\u001b[39m\r\n  \u001b[38;5;98m▀▀▀▀\u001b[39m|___|\u001b[38;5;98m▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀\u001b[39m\r\n\r\n\r\n"]
[5.383138, "o", "Version: 1.10\r\nLicence expiry: 2022-12-31\r\nFeatures: ['FAIRNESS', 'DIFFERENTIAL_PRIVACY']\r\n\r\n"]
[6.884954, "o", "Validation synthesis:\r\n====================\r\n"]
[7.887151, "o", "\r\n>>> df_meta = "]
[8.387151, "o", "MetaExtractor"]
[8.487151, "o", "."]
[8.587151, "o", "extract(df)"]
[8.887151, "o", "\r\n"]
[9.908142, "o", ">>> synthesizer"]
[9.983142, "o", " = "]
[10.06902, "o", "H"]
[10.138142, "o", "i"]
[10.28142, "o", "ghDimSynthesizer("]
[10.408142, "o", "df_meta=df_meta)"]
[10.67151, "o", "\r\n"]
[10.952282, "o", ">>> synthesizer.learn(df, num_iterations=100)\r\n"]
[18.964032, "o", "\rTraining Step 1 of 100 \u001b[38;5;212m╠▏                   ╣\u001b[39m - loss: 70.951  \r"]
[18.970418, "o", "\rTraining Step 2 of 100 \u001b[38;5;212m╠▍                   ╣\u001b[39m - loss: 69.013  \r"]
[18.976285, "o", "\rTraining Step 3 of 100 \u001b[38;5;212m╠▌                   ╣\u001b[39m - loss: 70.384  \r"]
[18.981784, "o", "\rTraining Step 4 of 100 \u001b[38;5;212m╠▊                   ╣\u001b[39m - loss: 70.078  \r"]
[18.987182, "o", "\rTraining Step 5 of 100 \u001b[38;5;212m╠█                   ╣\u001b[39m - loss: 45.422  \r"]
[18.992538, "o", "\rTraining Step 6 of 100 \u001b[38;5;212m╠█▏                  ╣\u001b[39m - loss: 62.575  \r"]
[18.997852, "o", "\rTraining Step 7 of 100 \u001b[38;5;212m╠█▍                  ╣\u001b[39m - loss: 55.075  \r"]
[19.003214, "o", "\rTraining Step 8 of 100 \u001b[38;5;212m╠█▌                  ╣\u001b[39m - loss: 46.711  \r"]
[19.008517, "o", "\rTraining Step 9 of 100 \u001b[38;5;212m╠█▊                  ╣\u001b[39m - loss: 68.344  \r"]
[19.013872, "o", "\rTraining Step 10 of 100 \u001b[38;5;212m╠██                  ╣\u001b[39m - loss: 61.215  \r"]
[19.019189, "o", "\rTraining Step 11 of 100 \u001b[38;5;212m╠██▏                 ╣\u001b[39m - loss: 51.227  \r"]
[19.024526, "o", "\rTraining Step 12 of 100 \u001b[38;5;212m╠██▍                 ╣\u001b[39m - loss: 31.998  \r"]
[19.029848, "o", "\rTraining Step 13 of 100 \u001b[38;5;212m╠██▌                 ╣\u001b[39m - loss: 40.177  \r"]
[19.035142, "o", "\rTraining Step 14 of 100 \u001b[38;5;212m╠██▊                 ╣\u001b[39m - loss: 52.221  \r"]
[19.040391, "o", "\rTraining Step 15 of 100 \u001b[38;5;212m╠███                 ╣\u001b[39m - loss: 31.429  \r"]
[19.045707, "o", "\rTraining Step 16 of 100 \u001b[38;5;212m╠███▏                ╣\u001b[39m - loss: 70.330  \r"]
[19.051045, "o", "\rTraining Step 17 of 100 \u001b[38;5;212m╠███▍                ╣\u001b[39m - loss: 33.479  \r"]
[19.056364, "o", "\rTraining Step 18 of 100 \u001b[38;5;212m╠███▌                ╣\u001b[39m - loss: 33.697  \r"]
[19.061661, "o", "\rTraining Step 19 of 100 \u001b[38;5;212m╠███▊                ╣\u001b[39m - loss: 35.721  \r"]
[19.066974, "o", "\rTraining Step 20 of 100 \u001b[38;5;212m╠████                ╣\u001b[39m - loss: 31.665  \r"]
[19.072308, "o", "\rTraining Step 21 of 100 \u001b[38;5;212m╠████▏               ╣\u001b[39m - loss: 49.341  \r"]
[19.077589, "o", "\rTraining Step 22 of 100 \u001b[38;5;212m╠████▍               ╣\u001b[39m - loss: 39.512  \r"]
[19.082884, "o", "\rTraining Step 23 of 100 \u001b[38;5;212m╠████▌               ╣\u001b[39m - loss: 34.787  \r"]
[19.088166, "o", "\rTraining Step 24 of 100 \u001b[38;5;212m╠████▊               ╣\u001b[39m - loss: 62.074  \r"]
[19.093486, "o", "\rTraining Step 25 of 100 \u001b[38;5;212m╠█████               ╣\u001b[39m - loss: 34.216  \r"]
[19.098845, "o", "\rTraining Step 26 of 100 \u001b[38;5;212m╠█████▏              ╣\u001b[39m - loss: 48.114  \r"]
[19.104205, "o", "\rTraining Step 27 of 100 \u001b[38;5;212m╠█████▍              ╣\u001b[39m - loss: 29.414  \r"]
[19.109597, "o", "\rTraining Step 28 of 100 \u001b[38;5;212m╠█████▌              ╣\u001b[39m - loss: 50.298  \r"]
[19.114958, "o", "\rTraining Step 29 of 100 \u001b[38;5;212m╠█████▊              ╣\u001b[39m - loss: 30.950  \r"]
[19.120465, "o", "\rTraining Step 30 of 100 \u001b[38;5;212m╠██████              ╣\u001b[39m - loss: 58.606  \r"]
[19.125985, "o", "\rTraining Step 31 of 100 \u001b[38;5;212m╠██████▏             ╣\u001b[39m - loss: 32.982  \r"]
[19.131652, "o", "\rTraining Step 32 of 100 \u001b[38;5;212m╠██████▍             ╣\u001b[39m - loss: 27.201  \r"]
[19.137181, "o", "\rTraining Step 33 of 100 \u001b[38;5;212m╠██████▌             ╣\u001b[39m - loss: 33.245  \r"]
[19.142583, "o", "\rTraining Step 34 of 100 \u001b[38;5;212m╠██████▊             ╣\u001b[39m - loss: 55.108  \r"]
[19.147943, "o", "\rTraining Step 35 of 100 \u001b[38;5;212m╠███████             ╣\u001b[39m - loss: 25.722  \r"]
[19.153332, "o", "\rTraining Step 36 of 100 \u001b[38;5;212m╠███████▏            ╣\u001b[39m - loss: 46.252  \r"]
[19.158648, "o", "\rTraining Step 37 of 100 \u001b[38;5;212m╠███████▍            ╣\u001b[39m - loss: 26.195  \r"]
[19.164012, "o", "\rTraining Step 38 of 100 \u001b[38;5;212m╠███████▌            ╣\u001b[39m - loss: 53.385  \r"]
[19.169341, "o", "\rTraining Step 39 of 100 \u001b[38;5;212m╠███████▊            ╣\u001b[39m - loss: 29.128  \r"]
[19.174644, "o", "\rTraining Step 40 of 100 \u001b[38;5;212m╠████████            ╣\u001b[39m - loss: 59.595  \r"]
[19.179917, "o", "\rTraining Step 41 of 100 \u001b[38;5;212m╠████████▏           ╣\u001b[39m - loss: 25.778  \r"]
[19.185277, "o", "\rTraining Step 42 of 100 \u001b[38;5;212m╠████████▍           ╣\u001b[39m - loss: 51.748  \r"]
[19.190703, "o", "\rTraining Step 43 of 100 \u001b[38;5;212m╠████████▌           ╣\u001b[39m - loss: 45.668  \r"]
[19.196149, "o", "\rTraining Step 44 of 100 \u001b[38;5;212m╠████████▊           ╣\u001b[39m - loss: 39.346  \r"]
[19.201568, "o", "\rTraining Step 45 of 100 \u001b[38;5;212m╠█████████           ╣\u001b[39m - loss: 32.744  \r"]
[19.206968, "o", "\rTraining Step 46 of 100 \u001b[38;5;212m╠█████████▏          ╣\u001b[39m - loss: 45.261  \r"]
[19.212581, "o", "\rTraining Step 47 of 100 \u001b[38;5;212m╠█████████▍          ╣\u001b[39m - loss: 35.254  \r"]
[19.218031, "o", "\rTraining Step 48 of 100 \u001b[38;5;212m╠█████████▌          ╣\u001b[39m - loss: 23.165  \r"]
[19.223642, "o", "\rTraining Step 49 of 100 \u001b[38;5;212m╠█████████▊          ╣\u001b[39m - loss: 35.915  \r"]
[19.229065, "o", "\rTraining Step 50 of 100 \u001b[38;5;212m╠██████████          ╣\u001b[39m - loss: 33.333  \r"]
[19.234459, "o", "\rTraining Step 51 of 100 \u001b[38;5;212m╠██████████▏         ╣\u001b[39m - loss: 29.790  \r"]
[19.239876, "o", "\rTraining Step 52 of 100 \u001b[38;5;212m╠██████████▍         ╣\u001b[39m - loss: 38.716  \r"]
[19.245294, "o", "\rTraining Step 53 of 100 \u001b[38;5;212m╠██████████▌         ╣\u001b[39m - loss: 39.142  \r"]
[19.250692, "o", "\rTraining Step 54 of 100 \u001b[38;5;212m╠██████████▊         ╣\u001b[39m - loss: 41.899  \r"]
[19.256135, "o", "\rTraining Step 55 of 100 \u001b[38;5;212m╠███████████         ╣\u001b[39m - loss: 30.723  \r"]
[19.261459, "o", "\rTraining Step 56 of 100 \u001b[38;5;212m╠███████████▏        ╣\u001b[39m - loss: 18.736  \r"]
[19.266831, "o", "\rTraining Step 57 of 100 \u001b[38;5;212m╠███████████▍        ╣\u001b[39m - loss: 25.399  \r"]
[19.272212, "o", "\rTraining Step 58 of 100 \u001b[38;5;212m╠███████████▌        ╣\u001b[39m - loss: 46.624  \r"]
[19.277557, "o", "\rTraining Step 59 of 100 \u001b[38;5;212m╠███████████▊        ╣\u001b[39m - loss: 49.371  \r"]
[19.282942, "o", "\rTraining Step 60 of 100 \u001b[38;5;212m╠████████████        ╣\u001b[39m - loss: 46.640  \r"]
[19.288278, "o", "\rTraining Step 61 of 100 \u001b[38;5;212m╠████████████▏       ╣\u001b[39m - loss: 24.056  \r"]
[19.293669, "o", "\rTraining Step 62 of 100 \u001b[38;5;212m╠████████████▍       ╣\u001b[39m - loss: 34.136  \r"]
[19.298992, "o", "\rTraining Step 63 of 100 \u001b[38;5;212m╠████████████▌       ╣\u001b[39m - loss: 50.210  \r"]
[19.304665, "o", "\rTraining Step 64 of 100 \u001b[38;5;212m╠████████████▊       ╣\u001b[39m - loss: 22.741  \r"]
[19.310028, "o", "\rTraining Step 65 of 100 \u001b[38;5;212m╠█████████████       ╣\u001b[39m - loss: 41.207  \r"]
[19.316347, "o", "\rTraining Step 66 of 100 \u001b[38;5;212m╠█████████████▏      ╣\u001b[39m - loss: 37.307  \r"]
[19.321711, "o", "\rTraining Step 67 of 100 \u001b[38;5;212m╠█████████████▍      ╣\u001b[39m - loss: 21.050  \r"]
[19.327941, "o", "\rTraining Step 68 of 100 \u001b[38;5;212m╠█████████████▌      ╣\u001b[39m - loss: 30.542  \r"]
[19.333319, "o", "\rTraining Step 69 of 100 \u001b[38;5;212m╠█████████████▊      ╣\u001b[39m - loss: 27.397  \r"]
[19.339628, "o", "\rTraining Step 70 of 100 \u001b[38;5;212m╠██████████████      ╣\u001b[39m - loss: 32.137  \r"]
[19.345033, "o", "\rTraining Step 71 of 100 \u001b[38;5;212m╠██████████████▏     ╣\u001b[39m - loss: 26.594  \r"]
[19.351042, "o", "\rTraining Step 72 of 100 \u001b[38;5;212m╠██████████████▍     ╣\u001b[39m - loss: 32.875  \r"]
[19.356386, "o", "\rTraining Step 73 of 100 \u001b[38;5;212m╠██████████████▌     ╣\u001b[39m - loss: 40.260  \r"]
[19.362548, "o", "\rTraining Step 74 of 100 \u001b[38;5;212m╠██████████████▊     ╣\u001b[39m - loss: 42.701  \r"]
[19.367863, "o", "\rTraining Step 75 of 100 \u001b[38;5;212m╠███████████████     ╣\u001b[39m - loss: 42.605  \r"]
[19.374061, "o", "\rTraining Step 76 of 100 \u001b[38;5;212m╠███████████████▏    ╣\u001b[39m - loss: 40.102  \r"]
[19.379728, "o", "\rTraining Step 77 of 100 \u001b[38;5;212m╠███████████████▍    ╣\u001b[39m - loss: 25.720  \r"]
[19.386207, "o", "\rTraining Step 78 of 100 \u001b[38;5;212m╠███████████████▌    ╣\u001b[39m - loss: 38.601  \r"]
[19.391593, "o", "\rTraining Step 79 of 100 \u001b[38;5;212m╠███████████████▊    ╣\u001b[39m - loss: 39.019  \r"]
[19.397741, "o", "\rTraining Step 80 of 100 \u001b[38;5;212m╠████████████████    ╣\u001b[39m - loss: 24.038  \r"]
[19.403112, "o", "\rTraining Step 81 of 100 \u001b[38;5;212m╠████████████████▏   ╣\u001b[39m - loss: 29.136  \r"]
[19.408468, "o", "\rTraining Step 82 of 100 \u001b[38;5;212m╠████████████████▍   ╣\u001b[39m - loss: 27.124  \r"]
[19.413954, "o", "\rTraining Step 83 of 100 \u001b[38;5;212m╠████████████████▌   ╣\u001b[39m - loss: 29.041  \r"]
[19.420301, "o", "\rTraining Step 84 of 100 \u001b[38;5;212m╠████████████████▊   ╣\u001b[39m - loss: 23.287  \r"]
[19.425777, "o", "\rTraining Step 85 of 100 \u001b[38;5;212m╠█████████████████   ╣\u001b[39m - loss: 56.485  \r"]
[19.432055, "o", "\rTraining Step 86 of 100 \u001b[38;5;212m╠█████████████████▏  ╣\u001b[39m - loss: 33.926  \r"]
[19.437512, "o", "\rTraining Step 87 of 100 \u001b[38;5;212m╠█████████████████▍  ╣\u001b[39m - loss: 28.178  \r"]
[19.443882, "o", "\rTraining Step 88 of 100 \u001b[38;5;212m╠█████████████████▌  ╣\u001b[39m - loss: 19.114  \r"]
[19.449441, "o", "\rTraining Step 89 of 100 \u001b[38;5;212m╠█████████████████▊  ╣\u001b[39m - loss: 28.236  \r"]
[19.455814, "o", "\rTraining Step 90 of 100 \u001b[38;5;212m╠██████████████████  ╣\u001b[39m - loss: 43.536  \r"]
[19.461212, "o", "\rTraining Step 91 of 100 \u001b[38;5;212m╠██████████████████▏ ╣\u001b[39m - loss: 22.052  \r"]
[19.467392, "o", "\rTraining Step 92 of 100 \u001b[38;5;212m╠██████████████████▍ ╣\u001b[39m - loss: 28.585  \r"]
[19.472774, "o", "\rTraining Step 93 of 100 \u001b[38;5;212m╠██████████████████▌ ╣\u001b[39m - loss: 24.946  \r"]
[19.478156, "o", "\rTraining Step 94 of 100 \u001b[38;5;212m╠██████████████████▊ ╣\u001b[39m - loss: 20.663  \r"]
[19.483491, "o", "\rTraining Step 95 of 100 \u001b[38;5;212m╠███████████████████ ╣\u001b[39m - loss: 53.589  \r"]
[19.488808, "o", "\rTraining Step 96 of 100 \u001b[38;5;212m╠███████████████████▏╣\u001b[39m - loss: 38.626  \r"]
[19.494223, "o", "\rTraining Step 97 of 100 \u001b[38;5;212m╠███████████████████▍╣\u001b[39m - loss: 24.579  \r"]
[19.499711, "o", "\rTraining Step 98 of 100 \u001b[38;5;212m╠███████████████████▌╣\u001b[39m - loss: 34.760  \r"]
[19.505107, "o", "\rTraining Step 99 of 100 \u001b[38;5;212m╠███████████████████▊╣\u001b[39m - loss: 28.355  \r"]
[19.51071, "o", "\rTraining Step 100 of 100 \u001b[38;5;212m╠████████████████████╣\u001b[39m - loss: 17.303  \r"]
[19.51093, "o", "\r\nDone.\r\n"]
[20.011721, "o", ">>> df_synth = synthesizer.synthesize(num_rows=100)\r\n\r\n"]
[20.652766, "o", "    SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines  age  NumberOfTime30-59DaysPastDueNotWorse  DebtRatio\r\n0                  0                              0.250418   58                                   0.0   0.291350\r\n1                  0                              0.342693   58                                   1.0   0.352459\r\n2                  0                              0.127222   53                                   0.0   0.301616\r\n3                  0                              0.361941   44                                   2.0   0.476291\r\n4                  0                              0.328527   45                                   3.0   0.388276\r\n..               ...                                   ...  ...                                   ...        ...\r\n95                 0                              0.197913   50                                   1.0   0.316396\r\n96                 0                              0.317961   51                                   3.0   0.316230"]
[20.652968, "o", "\r\n97                 0                              0.141359   38                                   0.0   0.256758\r\n98                 0                              0.141777   52                                   0.0   0.308033\r\n99                 1                              0.422652   43                                   3.0   0.378621\r\n\r\n[100 rows x 5 columns]\r\n"]
[21.653978, "o", "\r\n\u001b[38;5;35mSuccess!\u001b[39m\r\n"]
[22.374074, "o", "\u001b]0;synthesized@synthesized-sdk: ~\u0007\u001b[01;32msynthesized@synthesized-sdk\u001b[00m:\u001b[01;34m~\u001b[00m$ "]
[23.821995, "o", "\r\n"]
